{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_3tDg6ERSTt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VxO1iyyjzwj",
    "outputId": "9c1deed1-62e9-44e8-e044-75c700a29bc7"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qKbR5tpervXI"
   },
   "outputs": [],
   "source": [
    "class GreenHouseEnv(object):\n",
    "  def __init__(self,m,n,o):  #m, n and o is the dimension of the grid\n",
    "    #self.grid = np.zeros((m,n))\n",
    "    self.m = m\n",
    "    self.n = n\n",
    "    self.o = o\n",
    "    self.statePosDict ={}\n",
    "    self.statePositionDict(m,n,o)\n",
    "    #self.obsSpace = [[[k for k in range(self.o)] for j in range(self.n)] for i in range(self.m)]\n",
    "    self.obsSpace = [i for i in range(self.m * self.n * self.o)]\n",
    "    #print(self.obsSpace)\n",
    "    self.actSpace = {'U': 0, 'D': 1, 'L': 2, 'R': 3, 'B': 4, 'F': 5}\n",
    "    self.possibleAct = ['U','D','L','R', 'B', 'F']\n",
    "    self.addComponents()\n",
    "    self.rules_arr_rew = [9999,9999,0,0,0,0]\n",
    "    self.objectives_comp_1 = {\n",
    "        1: 'heater',\n",
    "        2: 'water tank'\n",
    "    }\n",
    "    self.rew_vec = [99999,99999,0,0,0,0] #6 is number of objectives\n",
    "    self.log_avg_d = []\n",
    "    self.log_best_d = []\n",
    "    self.rew_obtained = []\n",
    "    self.best_pos = [999,999,999]\n",
    "    self.best_pos_log = []\n",
    "    self.prev_distance = [99999,99999,0,0,0,0] #to keep record of the prev distance\n",
    "  def addComponents(self):\n",
    "    self.components = [1,2,3,4,5,6,7,8] #[1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "    if len(self.components)> self.m*self.n*self.o:\n",
    "      print('errorrrr')\n",
    "      return 0\n",
    "\n",
    "    \n",
    "    self.comp_dictionary = {\n",
    "        1: 'heater',\n",
    "        2: 'water tank',\n",
    "        3: 'pack soil',\n",
    "        4: 'heat sensor',\n",
    "        5: 'camera',\n",
    "        6: 'fan',\n",
    "        7: 'led',\n",
    "        8: 'water pump',\n",
    "        9: 'PCB',\n",
    "        10: 'Pipes'\n",
    "    }\n",
    "\n",
    "    #self.grid = np.zeros((self.m,self.n,self.o))\n",
    "    #print('grid: 111', self.grid)  \n",
    "    self.occupied = []\n",
    "    len_com = len(self.components)\n",
    "    i = 0\n",
    "    while len_com != 0:\n",
    "      #print('i',i)\n",
    "      x = random.choice(range(0,self.m))\n",
    "      y = random.choice(range(0,self.n))\n",
    "      z = random.choice(range(0,self.o))\n",
    "      if (x,y,z) not in self.occupied:\n",
    "        #self.grid[x,y,z] = components[i]\n",
    "        self.occupied.append((x,y,z))\n",
    "        len_com -= 1\n",
    "        i += 1\n",
    "      \n",
    "\n",
    "      #else:\n",
    "      #  x = random.choice(range(0,self.m))\n",
    "      #  y = random.choice(range(0,self.n))\n",
    "      #  z = random.choice(range(0,self.o))\n",
    "      #  self.grid[x,y,z] = components[i]\n",
    "      #  self.occupied.append((x,y,z))\n",
    "    #print('grid: ', np.shape(self.grid))   \n",
    "    print('occupied:',self.occupied)\n",
    "\n",
    "  def getComponentPosition(self, index):\n",
    "    return self.occupied[index]\n",
    "\n",
    "  def getComponentValue(self, pos):\n",
    "    if pos in self.occupied:\n",
    "      id = self.occupied.index(pos)\n",
    "      val = self.components[id]\n",
    "    else:\n",
    "      val = -1\n",
    "    return val\n",
    "\n",
    "  def setState(self, state, comp_id):\n",
    "    x,y,z = self.getComponentPosition(comp_id)\n",
    "    #self.grid[x,y,z] = -1\n",
    "    x,y,z = state\n",
    "    #self.grid[x,y,z] = components[comp_id]\n",
    "    self.occupied[comp_id] = state\n",
    "\n",
    "  def totalDistance(self, components):\n",
    "    total_dist = 0\n",
    "    for i in range(len(components)):\n",
    "      for j in range(len(components)):\n",
    "        i_pos = self.getComponentPosition(i+1)\n",
    "        j_pos = self.getComponentPosition(j+1)\n",
    "        dist_temp = self.calcDistance(i_pos, j_pos)\n",
    "        total_dist += dist_temp\n",
    "\n",
    "    return total_dist\n",
    "\n",
    "\n",
    "  def rewardComponents(self, component):\n",
    "    #print(self.rules_arr_rew)\n",
    "    total = 0\n",
    "    rew_comp = np.zeros(6) #6 here is number of objective\n",
    "    temp_rew_vec = np.zeros(6)\n",
    "\n",
    "\n",
    "    \n",
    "    #rule 1 - minimize distance between pack soil, water tank and water pump\n",
    "    if component == 2 or component == 3 or component == 8:\n",
    "      #print('RULE 1')\n",
    "      d1 = self.calcDistance(1,2)\n",
    "      d2 = self.calcDistance(2,7)\n",
    "      d3 = self.calcDistance(1,7)\n",
    "      avg_d = (d1 + d2 + d3)/3\n",
    "      #print('avg',avg_d)\n",
    "      \n",
    "      temp_rew_vec[0] = avg_d\n",
    "\n",
    "      #find diff from last distance and new distance\n",
    "      diff_1 = avg_d - self.rew_vec[0]\n",
    "      diff_2 = self.prev_distance[0] - self.rew_vec[0]\n",
    "\n",
    "      diff = diff_1 - diff_2\n",
    "\n",
    "      \n",
    "      #reward for moving closer or away from the best distance\n",
    "      if avg_d>self.prev_distance[0]: # move away\n",
    "        rew_comp[0] = -1\n",
    "      elif avg_d<self.prev_distance[0]: # move closer\n",
    "        #if it moves closer then check for the best score\n",
    "        if avg_d<self.rew_vec[0]: #set a new best score\n",
    "          rew_comp[0] = 10\n",
    "          self.rew_vec[0] = avg_d\n",
    "          pos1 = self.getComponentPosition(1)\n",
    "          pos2 = self.getComponentPosition(2)\n",
    "          pos3 = self.getComponentPosition(7)\n",
    "          self.best_pos = [pos1, pos2, pos3]\n",
    "          self.best_pos_log.append(self.best_pos)\n",
    "        elif avg_d==self.rew_vec[0]: #find a similar best score\n",
    "          rew_comp[0] = 5\n",
    "          #add code here later to save the coordinates if it is different from the previous one\n",
    "        else:\n",
    "          rew_comp[0] = 2\n",
    "      elif avg_d==self.prev_distance[0]: # stay in same place\n",
    "        rew_comp[0] = 0.5\n",
    "\n",
    "        \n",
    "\n",
    "      #save the new distance as prev distance\n",
    "      self.prev_distance[0] = avg_d\n",
    "      \n",
    "      '''\n",
    "      if avg_d<self.rew_vec[0]:\n",
    "        rew_comp[0] = 1\n",
    "        self.rew_vec[0] = avg_d\n",
    "        \n",
    "      elif avg_d>self.rew_vec[0]:\n",
    "        rew_comp[0] = -20\n",
    "      else:\n",
    "        rew_comp[0] = 0\n",
    "      '''\n",
    "      self.log_avg_d.append(avg_d)\n",
    "      self.log_best_d.append(self.rew_vec[0])\n",
    "      self.rew_obtained.append(rew_comp[0])\n",
    "      print('score obtained',rew_comp[0])\n",
    "      print('avg_d', avg_d)\n",
    "      print('slf.rew_vec', self.rew_vec[0])\n",
    "      print('reward',rew_comp[0])\n",
    "      \n",
    "      #total += rew1\n",
    "      #print('#MINIMIZE# old dist: ', self.rules_arr_rew[0], 'new dist:', avg_d ,'rew1:', rew1)\n",
    "    '''\n",
    "    #rule 2 - minimize distance between heater and the fan\n",
    "    if component == 1 or component == 6:\n",
    "      #print('RULE 2')\n",
    "      #print(self.rules_arr_rew)\n",
    "      hf = self.calcDistance(0,5)\n",
    "      #print('dist',hf)\n",
    "      \n",
    "      temp_rew_vec[1] = hf\n",
    "      if hf<self.rew_vec[1]:\n",
    "        rew_comp[1] = 1\n",
    "        \n",
    "      elif hf > self.rew_vec[1]:\n",
    "        rew_comp[1] = -1\n",
    "      else:\n",
    "        rew_comp[1] = 0\n",
    "      #print('#MINIMIZE# old dist: ', self.rules_arr_rew[1],'new dist:', hf , 'rew2:', rew2)\n",
    "\n",
    "    #rule 3 - maximize distance between LED and heat sensor\n",
    "    if component == 4 or component == 7:\n",
    "      #print('RULE 3')\n",
    "      lhs = self.calcDistance(3,6)\n",
    "      \n",
    "      temp_rew_vec[2] = lhs\n",
    "      if lhs>self.rew_vec[2]:\n",
    "        rew_comp[2] = 1\n",
    "        \n",
    "      elif lhs < self.rew_vec[2]:\n",
    "        rew_comp[2] = -1\n",
    "      else:\n",
    "        rew_comp[2] = 0\n",
    "      \n",
    "      #print('#MAXIMIZE# old dist: ', self.rules_arr_rew[2],'new dist:', lhs , 'rew3:', rew3)\n",
    "\n",
    "    #rule 4 - maximize distance between heater and heat sensor\n",
    "    \n",
    "    if component == 1 or component == 4:\n",
    "      #print('RULE 4')\n",
    "      hhs = self.calcDistance(0,3)\n",
    "      #print('hhs',hhs,'rules_arr',self.rules_arr_rew[3])\n",
    "      \n",
    "      temp_rew_vec[3] = hhs\n",
    "      if hhs>self.rew_vec[3]:\n",
    "        rew_comp[3] = 1\n",
    "        \n",
    "      elif hhs < self.rew_vec[3]:\n",
    "        rew_comp[3] = -1\n",
    "      else:\n",
    "        rew_comp[3] = 0\n",
    "      #print('#MAXIMIZE#  old dist: ', self.rules_arr_rew[3], 'new dist:', hhs ,'rew4:', rew4)\n",
    "    \n",
    "    #rule 5 - maximize lighting of pack soil by the LED\n",
    "    if component == 7 or component == 3:\n",
    "      #print('RULE 5')\n",
    "      x_1, y_1, z_1 = self.getComponentPosition(3)\n",
    "      z_1 = 0  #z moves to the top of the greenhouse\n",
    "      x_2, y_2, z_2 = self.getComponentPosition(7)\n",
    "      psl = math.sqrt((x_2 - x_1)**2 + (y_2 - y_1)**2 + (z_2 - z_1)**2)\n",
    "      \n",
    "      temp_rew_vec[4] = psl\n",
    "      if psl>self.rew_vec[4]:\n",
    "        rew_comp[4] = 1\n",
    "        \n",
    "      elif psl < self.rew_vec[4]:\n",
    "        rew_comp[4] = -1\n",
    "      else:\n",
    "        rew_comp[4] = 0\n",
    "      #print('#MAXIMIZE#  old dist: ', self.rules_arr_rew[4], 'new dist:', psl ,'rew5:', rew5)\n",
    "    \n",
    "    #rule 6 - maximize view of pack soil captured by the camera\n",
    "    if component == 5 or component == 3:\n",
    "      #print('RULE 6')\n",
    "      x_1, y_1, z_1 = self.getComponentPosition(3)\n",
    "      z_1 = 0  #z moves to the top of the greenhouse\n",
    "      x_2, y_2, z_2 = self.getComponentPosition(5)\n",
    "      psc = math.sqrt((x_2 - x_1)**2 + (y_2 - y_1)**2 + (z_2 - z_1)**2)\n",
    "      \n",
    "      temp_rew_vec[5] = psc\n",
    "      if psc>self.rew_vec[5]:\n",
    "        rew_comp[5] = 1\n",
    "        \n",
    "      elif psc < self.rew_vec[5]:\n",
    "        rew_comp[5] = -1\n",
    "      else:\n",
    "        rew_comp[5] = 0\n",
    "      #print('#MAXIMIZE#  old dist: ', self.rules_arr_rew[5], 'new dist:', psc , 'rew6:', rew6)\n",
    "    '''\n",
    "    return rew_comp,temp_rew_vec\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "  #handling in step func\n",
    "  def avoidOffGrid(self, newState, oldState):\n",
    "    if newState not in self.obsSpace:\n",
    "      return True\n",
    "    ##add code here\n",
    "\n",
    "  def step(self, action, comp_id): #,rule_val_arr\n",
    "    x,y,z = self.getComponentPosition(comp_id)\n",
    "    if action == 0:\n",
    "      #up\n",
    "      if z == 0:  #checking end of grid\n",
    "        new_z = z\n",
    "        nextState = (x,y,new_z)\n",
    "        \n",
    "      elif self.getComponentValue((x,y,z-1)) > 0:\n",
    "        new_z = z\n",
    "        nextState = (x,y,new_z)\n",
    "        \n",
    "      else:\n",
    "        new_z = z - 1\n",
    "        nextState = (x,y,new_z)\n",
    "      self.setState(nextState,comp_id)\n",
    "      st = self.posToState(tuple(nextState))\n",
    "      \n",
    "    elif action == 1:\n",
    "      #down\n",
    "      if z == self.o-1:\n",
    "        new_z = z\n",
    "        nextState = (x,y,new_z)\n",
    "      elif self.getComponentValue((x,y,z+1)) > 0:\n",
    "        new_z = z\n",
    "        nextState = (x,y,new_z)\n",
    "      else:\n",
    "        new_z = z + 1\n",
    "        nextState = (x,y,new_z)\n",
    "      self.setState(nextState,comp_id)\n",
    "      st = self.posToState(tuple(nextState))\n",
    "      \n",
    "      \n",
    "    elif action == 2:\n",
    "      #left\n",
    "      if x == 0:\n",
    "        new_x = x\n",
    "        nextState = (new_x,y,z)\n",
    "      elif self.getComponentValue((x-1,y,z)) > 0:\n",
    "        new_x = x\n",
    "        nextState = (new_x,y,z)\n",
    "      else:\n",
    "        new_x = x - 1\n",
    "        nextState = (new_x,y,z)\n",
    "      self.setState(nextState,comp_id)\n",
    "      st = self.posToState(tuple(nextState))\n",
    "      \n",
    "\n",
    "    elif action == 3:\n",
    "      #right\n",
    "      if x == self.m - 1:\n",
    "        new_x = x\n",
    "        nextState = (new_x,y,z)\n",
    "      elif self.getComponentValue((x+1,y,z)) > 0:\n",
    "        new_x = x\n",
    "        nextState = (new_x,y,z)\n",
    "      else:\n",
    "        new_x = x + 1\n",
    "        nextState = (new_x,y,z)\n",
    "      self.setState(nextState,comp_id)\n",
    "      st = self.posToState(tuple(nextState))\n",
    "      \n",
    "\n",
    "    elif action == 4:\n",
    "      #front\n",
    "      if y == 0:\n",
    "        new_y = y\n",
    "        nextState = (x,new_y,z)\n",
    "      elif self.getComponentValue((x,y-1,z)) > 0:\n",
    "        new_y = y\n",
    "        nextState = (x,new_y,z)\n",
    "      else:\n",
    "        new_y = y - 1\n",
    "        nextState = (x,new_y,z)\n",
    "      self.setState(nextState,comp_id)\n",
    "      st = self.posToState(tuple(nextState))\n",
    "      \n",
    "\n",
    "    elif action == 5:\n",
    "      #back\n",
    "      if y == self.n - 1:\n",
    "        new_y = y\n",
    "        nextState = (x,new_y,z)\n",
    "      elif self.getComponentValue((x,y+1,z)) > 0:\n",
    "        new_y = y\n",
    "        nextState = (x,new_y,z)\n",
    "      else:\n",
    "        new_y = y + 1\n",
    "        nextState = (x,new_y,z)\n",
    "      self.setState(nextState,comp_id)\n",
    "      st = self.posToState(tuple(nextState))\n",
    "      \n",
    "\n",
    "    elif action == 6:\n",
    "      #don't move\n",
    "      nextState = (x,y,z)\n",
    "      self.setState(nextState,comp_id)\n",
    "      st = self.posToState(tuple(nextState))\n",
    "      \n",
    "    t = comp_id + 1\n",
    "    rew,trv = self.rewardComponents(t)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    rew = list(rew)\n",
    "    dom = rew.count(1)\n",
    "    non_dom = rew.count(-1)\n",
    "    #print('rew', rew)\n",
    "    #print('dom', dom)\n",
    "    #print('non dom', non_dom)\n",
    "    '''\n",
    "    if dom>non_dom:\n",
    "      reward_ret = 1\n",
    "      self.rew_vec = trv\n",
    "      #print('mi aahe')\n",
    "    elif dom<non_dom:\n",
    "      reward_ret = -1\n",
    "      #print('mi nai')\n",
    "    else:\n",
    "      reward_ret = 0.5\n",
    "      if random.uniform(0,1) < 0.5:\n",
    "        self.rew_vec = trv            \n",
    "    '''\n",
    "\n",
    "    \n",
    "\n",
    "    '''\n",
    "    dis = self.calcDistance(1,2)\n",
    "    if dis <= self.dist_arr[0]:\n",
    "      reward = 1\n",
    "      self.dist_arr[0] = dis\n",
    "    else:\n",
    "      reward = -1\n",
    "    '''\n",
    "    #print('next state innn', st)\n",
    "    return st, rew[0]\n",
    "\n",
    "  def tupleToState(self, tup):\n",
    "    tem = ''\n",
    "    for i in tup:\n",
    "      s = str(i)\n",
    "      tem = tem + s\n",
    "    tem = int(tem)\n",
    "\n",
    "    return tem\n",
    "\n",
    "  \n",
    "\n",
    "  def step_main(self,state, act,comp_id_1, comp_id_2):\n",
    "    act_1 = int(act/7)\n",
    "    act_2 = int(act%7)\n",
    "\n",
    "    print('action 1: ', act_1)\n",
    "    print('action 2: ', act_2)\n",
    "    self.step(act_1,comp_id_1)\n",
    "    self.step(act_2,comp_id_2)\n",
    "    \n",
    "    dis = self.calcDistance(comp_id_1,comp_id_2)\n",
    "    if dis <= self.dist_arr[0]:\n",
    "      reward = 1\n",
    "    else:\n",
    "      reward = -1\n",
    "    \n",
    "    idx1 = comp_id_1 - 1\n",
    "    idx2 = comp_id_2 - 1\n",
    "\n",
    "    pos1 = self.getComponentPosition(idx1)\n",
    "    pos2 = self.getComponentPosition(idx2)\n",
    "    print('Comp',comp_id_1,' pos is: ',pos1)\n",
    "    print('Comp',comp_id_2,' pos is: ',pos2)\n",
    "\n",
    "    next_state = pos1 + pos2\n",
    "    next_state = self.tupleToState(next_state)\n",
    "\n",
    "    if dis<= 3:\n",
    "      done = True\n",
    "    else:\n",
    "      done = False\n",
    "\n",
    "    return next_state, reward, done\n",
    "\n",
    "  def statePositionDict(self,m,n,o):\n",
    "    cnt = 0\n",
    "    for i in range(m):\n",
    "      for j in range(n):\n",
    "        for k in range(o):\n",
    "          self.statePosDict[cnt] = (i,j,k)\n",
    "          cnt += 1\n",
    "    \n",
    "  def posToState(self,tup):\n",
    "    #print(self.statePosDict)\n",
    "    for k,v in self.statePosDict.items():\n",
    "      if v == tup:\n",
    "        ptos = k\n",
    "    return ptos\n",
    "\n",
    "  def stateToPos(self,s):\n",
    "    ret = self.statePosDict[s]\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "  def calcDistance(self, comp_id_1, comp_id_2):\n",
    "    x_1, y_1, z_1 = self.getComponentPosition(comp_id_1)\n",
    "    x_2, y_2, z_2 = self.getComponentPosition(comp_id_2)\n",
    "    dist = math.sqrt((x_2 - x_1)**2 + (y_2 - y_1)**2 + (z_2 - z_1)**2)\n",
    "    return dist\n",
    "\n",
    "  \n",
    "  def reset(self):\n",
    "    #self.grid = np.zeros((self.m, self.n,self.o))\n",
    "    self.__init__(self.m, self.n,self.o)\n",
    "\n",
    "  def render(self):\n",
    "    #print(self.occupied)\n",
    "    print('components',self.components)\n",
    "    #print(\n",
    "    #    '#####################################################################'+\n",
    "    #    '#####################################################################'\n",
    "    #    +'########################')\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    for tup in self.occupied:\n",
    "      x.append(tup[0])\n",
    "      y.append(tup[1])\n",
    "      z.append(tup[2])\n",
    "    \n",
    "    print('*****FRONT VIEW*****')\n",
    "    print('Z_AXIS \\u2193')\n",
    "    \n",
    "    i=1\n",
    "    for y_id in range(self.n):\n",
    "      print('LAYER_',y_id)\n",
    "      for i in range(self.m):\n",
    "        print('################',end='')\n",
    "      print()\n",
    "      for z_id in range((self.o)):\n",
    "        for x_id in range((self.m)):\n",
    "          print('|',end='\\t')\n",
    "          temp = self.getComponentValue((x_id,y_id,z_id))\n",
    "          if temp>0:\n",
    "            print(temp,end='\\t')\n",
    "            #i+=1\n",
    "          else:\n",
    "            print(-1, end='\\t')\n",
    "        print('|',end='\\t')\n",
    "        print()\n",
    "        for i in range(self.m):\n",
    "          print('################',end='')\n",
    "        print()\n",
    "    print('X_AXIS \\u2192')\n",
    "    print('\\n\\n')\n",
    "    print('*****TOP VIEW*****')\n",
    "    print('Y_AXIS \\u2193')\n",
    "    \n",
    "    i=1\n",
    "    for z_id in range(self.o):\n",
    "      print('LAYER_',z_id)\n",
    "      for i in range(self.m):\n",
    "        print('################',end='')\n",
    "      print()\n",
    "      for y_id in range((self.n)):\n",
    "        for x_id in range((self.m)):\n",
    "          print('|',end='\\t')\n",
    "          temp = self.getComponentValue((x_id,y_id,z_id))\n",
    "          if temp>0:\n",
    "            print(temp,end='\\t')\n",
    "          #  i+=1\n",
    "          else:\n",
    "            print(-1, end='\\t')\n",
    "        print('|',end='\\t')\n",
    "        print()\n",
    "        for i in range(self.m):\n",
    "          print('################',end='')\n",
    "        print()\n",
    "      print('X_AXIS \\u2192')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7rtc416blnE"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "class Agent:\n",
    "  def __init__(self, eps_prob):\n",
    "    self.time_step = 0\n",
    "    self.eps_prob = eps_prob\n",
    "    self.total_rew = 0\n",
    "    self.prev_action = None\n",
    "    self.action_cnt = 0\n",
    "    self.action_log = []\n",
    "    \n",
    "    \n",
    "\n",
    "  def greedy_eps(self, Q, eps, num_act):\n",
    "    #https://www.geeksforgeeks.org/q-learning-in-python/\n",
    "    #https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/\n",
    "\n",
    "    def policyFunc(state):\n",
    "      act_prob = np.ones(num_act, dtype = float) * eps / num_act\n",
    "\n",
    "      best_act = np.argmax(Q[state])\n",
    "      act_prob[best_act] += (1 - eps)\n",
    "      \n",
    "      return act_prob\n",
    "\n",
    "    return policyFunc\n",
    "\n",
    "  def qLearning(self, env, nS, nA, num_episodes, disc_fac = 1.0, alpha = 0.5, epsilon = 0.1):\n",
    "    \n",
    "    Q = np.zeros((nS,nA)) #num of action hardcoded\n",
    "    \n",
    "\n",
    "\n",
    "    for x in range(num_episodes):\n",
    "      env.reset()\n",
    "      \n",
    "      for i in [1,2,7]:\n",
    "      \n",
    "        \n",
    "        state = env.getComponentPosition(i)\n",
    "        state = env.posToState(state)\n",
    "        done = False\n",
    "\n",
    "        reward_total = 0\n",
    "        start = time.time()\n",
    "\n",
    "        reward_log = [] #np.array(3000)\n",
    "\n",
    "        reward_total_log = [] #np.array(7)\n",
    "\n",
    "        while not done:\n",
    "          if random.uniform(0,1) < epsilon:\n",
    "            action = np.random.choice(7)\n",
    "            self.action_log.append(0) # 0 for random action\n",
    "          else:\n",
    "            action = np.argmax(Q[state])\n",
    "            self.action_log.append(1) # 1 for best action\n",
    "          #print('action',action)\n",
    "          next_state, reward = env.step(action, i)\n",
    "\n",
    "          reward_total += reward\n",
    "          print('reward total', reward_total)\n",
    "          reward_log.append(reward)\n",
    "\n",
    "          old_val = Q[state, action]\n",
    "          next_max = np.max(Q[next_state])\n",
    "\n",
    "          new_value = (1 - alpha) * old_val + alpha * (reward + disc_fac * next_max)\n",
    "\n",
    "          Q[state,action] = new_value\n",
    "\n",
    "          state = next_state\n",
    "\n",
    "          end = time.time()\n",
    "\n",
    "          diff = end - start\n",
    "\n",
    "          \n",
    "\n",
    "          if reward_total>50000:# or diff>90:\n",
    "            done = True\n",
    "            print('ep:',x)\n",
    "            print('rew_tot', reward_total)\n",
    "            print('diff', diff)\n",
    "        \n",
    "        reward_total_log.append(reward_total)\n",
    "\n",
    "        reward_log = np.array(reward_log)\n",
    "        reward_total_log = np.array(reward_total_log)\n",
    "\n",
    "        reward_file_name = 'reward_random_'+str(x)+'_'+str(i)\n",
    "\n",
    "        avg_d_glog = np.array(env.log_avg_d)\n",
    "        best_d_glog = np.array(env.log_best_d)\n",
    "        rew_obt_glog = np.array(env.rew_obtained)\n",
    "      \n",
    "        reward_avg_d_file_name = 'avg_d_glog'+str(x)+'_'+str(i)        \n",
    "        np.save('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_avg_d_file_name+'.npy', avg_d_glog)\n",
    "\n",
    "        reward_best_d_file_name = 'best_d_glog'+str(x)+'_'+str(i)\n",
    "        np.save('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_best_d_file_name+'.npy', best_d_glog)\n",
    "\n",
    "        reward_rew_obt_file_name = 'rew_obt_glog'+str(x)+'_'+str(i)        \n",
    "        np.save('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_rew_obt_file_name+'.npy', rew_obt_glog)\n",
    "\n",
    "        reward_best_pos_log_obt_file_name = 'rew_best_pos_glog'+str(x)+'_'+str(i)        \n",
    "        np.save('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_best_pos_log_obt_file_name+'.npy', env.best_pos_log)\n",
    "\n",
    "        reward_act_log_obt_file_name = 'rew_act_glog'+str(x)+'_'+str(i)        \n",
    "        np.save('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_act_log_obt_file_name+'.npy', self.action_log)\n",
    "        \n",
    "        #np.save('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_file_name+'.npy', reward_log)\n",
    "      \n",
    "      #reward_total_file_name = 'reward_total_random_'+str(num_episodes)\n",
    "      #np.save('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_total_file_name+'.npy', reward_total_log)\n",
    "          \n",
    "    \n",
    "    '''\n",
    "    #print(Q)\n",
    "    policy = self.greedy_eps(Q, epsilon, 7)\n",
    "\n",
    "    for i in range(num_episodes):\n",
    "      env.reset()\n",
    "      #state = \n",
    "      #for i in itertools.count():\n",
    "\n",
    "        #action_probabilities = policy()\n",
    "\n",
    "\n",
    "    for x in range(num_episodes):\n",
    "      \n",
    "      \n",
    "      for i in range(7): #hardcoded to 10 components\n",
    "        \n",
    "        state = env.getComponentPosition(i) #np.random.choice(self.nS)\n",
    "        #print(state)\n",
    "        state = env.posToState(state)\n",
    "        done = False\n",
    "        #cnt = 0\n",
    "        reward_total = 0\n",
    "        while not done:\n",
    "          #pdb.set_trace()\n",
    "          #print('comp',i)\n",
    "          #print('episode', x)\n",
    "          if random.uniform(0,1) < epsilon:\n",
    "            #print('random act')\n",
    "            action = np.random.choice(7) #7 is number of actions //hardcoded\n",
    "          else:\n",
    "            #print('best act')\n",
    "            action = np.argmax(Q[state])\n",
    "\n",
    "          #print('state',state)\n",
    "          #print('act',action)\n",
    "          next_state, reward = env.step(action, i)\n",
    "          #print('next state', next_state)\n",
    "          #print('reward', reward)\n",
    "          \n",
    "          reward_total += reward\n",
    "\n",
    "          #print('reward_total',reward_total)\n",
    "\n",
    "          #print('HELLO',next_state)\n",
    "          old_val = Q[state, action]\n",
    "          next_max = np.max(Q[next_state])\n",
    "\n",
    "          new_value = (1 - alpha) * old_val + alpha * (reward + disc_fac * next_max)\n",
    "\n",
    "          Q[state,action] = new_value\n",
    "\n",
    "          state = next_state\n",
    "\n",
    "          #cnt += 1\n",
    "          \n",
    "          if reward_total>50:\n",
    "            done = True\n",
    "            print('comp',i)\n",
    "            print('episode', x)\n",
    "            print('final value',reward_total)\n",
    "          \n",
    "         ''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E0nbhgNK1ZI1",
    "outputId": "9bc24709-643d-4a5e-a052-7c4421714a9d"
   },
   "outputs": [],
   "source": [
    "env = GreenHouseEnv(100 ,100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OCglRNWSrwq1"
   },
   "outputs": [],
   "source": [
    "agent = Agent(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vG3irsyjsIpx",
    "outputId": "874433fa-4387-412d-8c00-897f5cc54854"
   },
   "outputs": [],
   "source": [
    "agent.qLearning(env=env,nS=100*100*100,nA=7,num_episodes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U_f9hM_W-fLa"
   },
   "outputs": [],
   "source": [
    "reward_best_d_file_name = 'best_d_glog'+str(0)+'_'+str(1)\n",
    "best_d = np.load('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_best_d_file_name+'.npy')\n",
    "\n",
    "reward_avg_d_file_name = 'avg_d_glog'+str(0)+'_'+str(1)        \n",
    "avg_d = np.load('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_avg_d_file_name+'.npy')\n",
    "\n",
    "reward_rew_obt_file_name = 'rew_obt_glog'+str(0)+'_'+str(1)        \n",
    "rew_obt = np.load('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_rew_obt_file_name+'.npy')\n",
    "\n",
    "reward_best_pos_log_obt_file_name = 'rew_best_pos_glog'+str(0)+'_'+str(1)        \n",
    "best_pos = np.load('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_best_pos_log_obt_file_name+'.npy')\n",
    "\n",
    "reward_act_log_obt_file_name = 'rew_act_glog'+str(0)+'_'+str(1)        \n",
    "act_log = np.load('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_act_log_obt_file_name+'.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "QXWDMU3a_igA",
    "outputId": "272250af-baa0-40d5-9110-877bbb5100f4"
   },
   "outputs": [],
   "source": [
    "plt.plot(best_d[0:100])\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('best distance')\n",
    "plt.title('Best distance over first 100 steps [component 1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "HmHc1C2ru6d6",
    "outputId": "002c58b1-edfe-4baa-a977-d068f8b114a9"
   },
   "outputs": [],
   "source": [
    "plt.plot(best_d)\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('distance')\n",
    "plt.title('Best distance over all steps[component 1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "kRP6Yk3mvMMV",
    "outputId": "a603bae8-b0ab-43e4-bb26-8bd8151959cf"
   },
   "outputs": [],
   "source": [
    "plt.plot(avg_d[0:200])\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('avg dist')\n",
    "plt.title('Average Distance between components[first 200 steps] for comp 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "Q-h0K5akvDR3",
    "outputId": "96ede3ae-6f90-42c6-f7fa-a19dbc830c69"
   },
   "outputs": [],
   "source": [
    "plt.plot(avg_d)\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('avg dist')\n",
    "plt.title('Average Distance between components - comp1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNf16i_ZyKP9"
   },
   "outputs": [],
   "source": [
    "point_five = list(rew_obt==0.5).count(True)\n",
    "neg_rew = list(rew_obt==-1).count(True)\n",
    "rew_two = list(rew_obt==2).count(True)\n",
    "rew_five = list(rew_obt==5).count(True)\n",
    "rew_ten = list(rew_obt==10).count(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "i07fgYOUxeWd",
    "outputId": "ea935f48-4b32-4176-c980-e334bc299726"
   },
   "outputs": [],
   "source": [
    "x = ['-1','0.5','2','5','10']\n",
    "y = [neg_rew, point_five, rew_two, rew_five, rew_ten]\n",
    "plt.bar(x,y)\n",
    "plt.xlabel('Reward')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Rewards for component 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "a5UBde2-0Xu7",
    "outputId": "198d90e3-6958-417b-de86-f1e9ab22a08c"
   },
   "outputs": [],
   "source": [
    "x = ['5','10']\n",
    "y = [rew_five, rew_ten]\n",
    "plt.bar(x,y)\n",
    "plt.xlabel('Reward')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Rewards for component 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "_pwq3lvg-fCD",
    "outputId": "fed4c857-d6b7-4c82-def1-1cb8c93c90cb"
   },
   "outputs": [],
   "source": [
    "random_action_cnt = list(act_log).count(0)\n",
    "best_action_cnt = list(act_log).count(1)\n",
    "x = ['random','best']\n",
    "y = [random_action_cnt,best_action_cnt]\n",
    "plt.bar(x,y)\n",
    "plt.xlabel('Action')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Exploit vs Explore for component 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcazMJVn1ngk"
   },
   "outputs": [],
   "source": [
    "reward_best_d_file_name = 'best_d_glog'+str(0)+'_'+str(2)\n",
    "best_d = np.load('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_best_d_file_name+'.npy')\n",
    "\n",
    "reward_avg_d_file_name = 'avg_d_glog'+str(0)+'_'+str(2)        \n",
    "avg_d = np.load('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_avg_d_file_name+'.npy')\n",
    "\n",
    "reward_rew_obt_file_name = 'rew_obt_glog'+str(0)+'_'+str(2)        \n",
    "rew_obt = np.load('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_rew_obt_file_name+'.npy')\n",
    "\n",
    "reward_best_pos_log_obt_file_name = 'rew_best_pos_glog'+str(0)+'_'+str(2)        \n",
    "best_pos = np.load('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_best_pos_log_obt_file_name+'.npy')\n",
    "\n",
    "reward_act_log_obt_file_name = 'rew_act_glog'+str(0)+'_'+str(2)        \n",
    "act_log = np.load('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_act_log_obt_file_name+'.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "Tk0Nwsc32Ah-",
    "outputId": "39ac6331-64b7-4446-b52b-b003e7133844"
   },
   "outputs": [],
   "source": [
    "plt.plot(best_d[0:100])\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('best distance')\n",
    "plt.title('Best distance over first 100 steps [component 2]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "T6GexQBD2J0j",
    "outputId": "3b1df397-1001-4fdf-bda4-1af7e1c39b80"
   },
   "outputs": [],
   "source": [
    "plt.plot(best_d)\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('distance')\n",
    "plt.title('Best distance over all steps[component 2]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "iCPCEwKy2SZz",
    "outputId": "32b3757b-e3f9-4869-903f-0dd2b0d75afc"
   },
   "outputs": [],
   "source": [
    "plt.plot(avg_d[0:200])\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('avg dist')\n",
    "plt.title('Average Distance between components[first 200 steps] for comp 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "tPpE1mkE2eQ7",
    "outputId": "7cee6987-d1e3-43ce-8cef-bd474bce38c1"
   },
   "outputs": [],
   "source": [
    "plt.plot(avg_d)\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('avg dist')\n",
    "plt.title('Average Distance between components - comp 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_zQDcuk22ei"
   },
   "outputs": [],
   "source": [
    "point_five = list(rew_obt==0.5).count(True)\n",
    "neg_rew = list(rew_obt==-1).count(True)\n",
    "rew_two = list(rew_obt==2).count(True)\n",
    "rew_five = list(rew_obt==5).count(True)\n",
    "rew_ten = list(rew_obt==10).count(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "9U2atTtP2nPS",
    "outputId": "39aeb13d-47ae-45d8-ad59-c929943025bf"
   },
   "outputs": [],
   "source": [
    "x = ['-1','0.5','2','5','10']\n",
    "y = [neg_rew, point_five, rew_two, rew_five, rew_ten]\n",
    "plt.bar(x,y)\n",
    "plt.xlabel('Reward')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Rewards for component 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "KjJHllnd2kUu",
    "outputId": "d4ac16a1-f638-432c-d8cb-7080fcd29ea5"
   },
   "outputs": [],
   "source": [
    "x = ['5','10']\n",
    "y = [rew_five, rew_ten]\n",
    "plt.bar(x,y)\n",
    "plt.xlabel('Reward')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Rewards for component 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "BWCNjpyp3Kg4",
    "outputId": "6b3d43df-ebfe-4f9b-c3da-d9b5e9e3f264"
   },
   "outputs": [],
   "source": [
    "random_action_cnt = list(act_log).count(0)\n",
    "best_action_cnt = list(act_log).count(1)\n",
    "x = ['random','best']\n",
    "y = [random_action_cnt,best_action_cnt]\n",
    "plt.bar(x,y)\n",
    "plt.xlabel('Action')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Exploit vs Explore for component 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KBGvmmG1oG5"
   },
   "outputs": [],
   "source": [
    "reward_best_d_file_name = 'best_d_glog'+str(0)+'_'+str(7)\n",
    "best_d = np.load('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_best_d_file_name+'.npy')\n",
    "\n",
    "reward_avg_d_file_name = 'avg_d_glog'+str(0)+'_'+str(7)        \n",
    "avg_d = np.load('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_avg_d_file_name+'.npy')\n",
    "\n",
    "reward_rew_obt_file_name = 'rew_obt_glog'+str(0)+'_'+str(7)        \n",
    "rew_obt = np.load('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_rew_obt_file_name+'.npy')\n",
    "\n",
    "reward_best_pos_log_obt_file_name = 'rew_best_pos_glog'+str(0)+'_'+str(7)        \n",
    "best_pos = np.load('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_best_pos_log_obt_file_name+'.npy')\n",
    "\n",
    "reward_act_log_obt_file_name = 'rew_act_glog'+str(0)+'_'+str(7)        \n",
    "act_log = np.load('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_act_log_obt_file_name+'.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "ud-D6OuX3Vgx",
    "outputId": "d42c17e1-8740-4e3c-f75f-39fde141b4ae"
   },
   "outputs": [],
   "source": [
    "plt.plot(best_d[0:100])\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('best distance')\n",
    "plt.title('Best distance over first 100 steps [component 7]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "ft3VzQGI3b-9",
    "outputId": "d0135675-2ef7-4537-b66a-4110f7070f18"
   },
   "outputs": [],
   "source": [
    "plt.plot(best_d)\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('distance')\n",
    "plt.title('Best distance over all steps[component 7]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "7DPH2Awe3wnV",
    "outputId": "9ef37a46-3739-4da5-d2e7-861de1a37381"
   },
   "outputs": [],
   "source": [
    "plt.plot(avg_d[0:200])\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('avg dist')\n",
    "plt.title('Average Distance between components[first 200 steps] for comp 7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "ge6bXZFo31v3",
    "outputId": "838fe1c7-92a0-42dc-eb30-7bf7ad436781"
   },
   "outputs": [],
   "source": [
    "plt.plot(avg_d)\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('avg dist')\n",
    "plt.title('Average Distance between components - comp 7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FjMHh46p3_31"
   },
   "outputs": [],
   "source": [
    "point_five = list(rew_obt==0.5).count(True)\n",
    "neg_rew = list(rew_obt==-1).count(True)\n",
    "rew_two = list(rew_obt==2).count(True)\n",
    "rew_five = list(rew_obt==5).count(True)\n",
    "rew_ten = list(rew_obt==10).count(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "8Xh5uu1A4ED4",
    "outputId": "29a3276b-ff2d-4284-ac01-e654bbb44901"
   },
   "outputs": [],
   "source": [
    "x = ['-1','0.5','2','5','10']\n",
    "y = [neg_rew, point_five, rew_two, rew_five, rew_ten]\n",
    "plt.bar(x,y)\n",
    "plt.xlabel('Reward')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Rewards for component 7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "9rnQUcAb4Yi1",
    "outputId": "b9147d73-eaa0-46c6-fb50-dcec6fa05b52"
   },
   "outputs": [],
   "source": [
    "x = ['5','10']\n",
    "y = [rew_five, rew_ten]\n",
    "plt.bar(x,y)\n",
    "plt.xlabel('Reward')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Rewards for component 7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "Ez5-z1mC4cdA",
    "outputId": "33799cbf-20ba-407f-ffc0-6348df9f6188"
   },
   "outputs": [],
   "source": [
    "random_action_cnt = list(act_log).count(0)\n",
    "best_action_cnt = list(act_log).count(1)\n",
    "x = ['random','best']\n",
    "y = [random_action_cnt,best_action_cnt]\n",
    "plt.bar(x,y)\n",
    "plt.xlabel('Action')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Exploit vs Explore for component 7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2uax4CIitUKu",
    "outputId": "e1efadb9-9222-4013-9166-4695d5be6aba"
   },
   "outputs": [],
   "source": [
    "env.getComponentPosition(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vxHGXW3WRFL",
    "outputId": "f2e7f653-1d0b-463d-812f-0312262393d6"
   },
   "outputs": [],
   "source": [
    "env.getComponentPosition(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HE4a7RxwifV6"
   },
   "source": [
    "Env space = 10x5x5 (1,2,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "lEE7xZyjgnT2",
    "outputId": "a782d8eb-48bb-4228-eb91-dc61b30a51fa"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(env.log_avg_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "4_Bn983fg3db",
    "outputId": "c9b719e4-0ede-40d6-9160-eef00e817118"
   },
   "outputs": [],
   "source": [
    "plt.plot(env.log_best_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "otutREErphYL",
    "outputId": "a5c84cf7-8dee-4b8a-e486-ce3d08d040b3"
   },
   "outputs": [],
   "source": [
    "for x in range(90,100):\n",
    "  for i in [1]:\n",
    "    reward_avg_d_file_name = 'avg_d_glog'+str(x)+'_'+str(i) \n",
    "    arr = np.load('/content/drive/MyDrive/ProdDesign_Numpy/'+reward_avg_d_file_name+'.npy')\n",
    "    plt.plot(arr, label=reward_avg_d_file_name)\n",
    "    plt.legend()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saWzyBfPhi98"
   },
   "source": [
    "Try with 10x10x10 (1,2,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "wxbod4pQhijc",
    "outputId": "e72e590b-bd33-4963-d09d-dec4d5db02df"
   },
   "outputs": [],
   "source": [
    "plt.plot(env.log_avg_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "OrZn1In0hsH7",
    "outputId": "faf13b5c-5110-4274-a2db-0ee11cb48001"
   },
   "outputs": [],
   "source": [
    "plt.plot(env.log_best_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "XyR2ZC1VkXlE",
    "outputId": "825961cc-0ea3-4dba-996a-97ac5a4e3147"
   },
   "outputs": [],
   "source": [
    "plt.plot(env.log_avg_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "-s04oIB7kYeb",
    "outputId": "9787614f-3c52-4819-a8ac-62d744d91288"
   },
   "outputs": [],
   "source": [
    "plt.plot(env.log_best_d)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Objective1_Minimize_Distance_QLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
